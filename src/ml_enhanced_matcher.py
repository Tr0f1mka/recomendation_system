import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
import joblib
import os
from typing import Dict, List

class MLEnhancer:
    """ML Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹"""
    
    def __init__(self):
        self.model = RandomForestRegressor(
            n_estimators=50, 
            random_state=42, 
            max_depth=10,
            min_samples_split=5
        )
        self.scaler = StandardScaler()
        self.is_trained = False
        
    def train(self, training_data: List[Dict]):
        """ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""
        if not training_data:
            print("âš ï¸ ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ML Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")
            return False
            
        print(f"ğŸ§  ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ML Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° {len(training_data)} Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°Ñ…...")
        
        try:
            X = []
            y = []
            
            for record in training_data:
                features = self._extract_features(record)
                X.append(features)
                y.append(record.get('conversion_rate', 0.5))
            
            X_array = np.array(X)
            
            # ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼ Ñ„Ğ¸Ñ‡Ğ¸
            X_scaled = self.scaler.fit_transform(X_array)
            
            # ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
            self.model.fit(X_scaled, y)
            self.is_trained = True
            
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
            os.makedirs("models", exist_ok=True)
            joblib.dump({
                'model': self.model,
                'scaler': self.scaler
            }, 'models/ml_enhancer.pkl')
            
            score = self.model.score(X_scaled, y)
            print(f"âœ… ML Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ°! RÂ² score: {score:.3f}")
            return True
            
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ML Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {e}")
            return False
    
    def predict(self, user_profile: Dict, product: Dict) -> float:
        """ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ score Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ML Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"""
        if not self.is_trained:
            return 0.5
            
        try:
            features = self._extract_features({
                'user_profile': user_profile,
                'product': product
            })
            features_scaled = self.scaler.transform([features])
            prediction = self.model.predict(features_scaled)[0]
            return float(np.clip(prediction, 0, 1))
        except Exception as e:
            print(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° ML Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ: {e}")
            return 0.5
    
    def optimize(self, base_score: float, user_profile: Dict, product: Dict) -> float:
        """ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ML"""
        ml_score = self.predict(user_profile, product)
        optimized_score = base_score * 0.6 + ml_score * 0.4
        return round(optimized_score, 3)
    
    def _extract_features(self, record: Dict) -> List[float]:
        """Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ² Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""
        user_profile = record['user_profile']
        product = record['product']
        
        features = [
            # Ğ¤Ğ¸Ñ‡Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
            user_profile.get('total_spent', 0),
            user_profile.get('avg_transaction_value', 0),
            self._map_activity_level(user_profile.get('interaction_frequency', 'unknown')),
            user_profile.get('category_diversity', 0),
            
            # Ğ¤Ğ¸Ñ‡Ğ¸ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ°
            product.get('business_value', 0.5),
            
            # Ğ’Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ
            self._calculate_spending_match(user_profile, product)
        ]
        
        return features
    def load_model(self, model_path: str = "models/ml_enhancer.pkl"):
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¿Ñ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"""
        try:
            if os.path.exists(model_path):
                model_data = joblib.load(model_path)
                self.model = model_data['model']
                self.scaler = model_data['scaler']
                self.is_trained = True
                print("âœ… ML Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ° Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ°")
            else:
                print("âš ï¸ Ğ¤Ğ°Ğ¹Ğ» Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½, Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ°")
        except Exception as e:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {e}")

    def train_model(self, training_data: List[Dict]):
        """ĞĞ»Ğ¸Ğ°Ñ Ğ´Ğ»Ñ train Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸"""
        return self.train(training_data)
    
    def _map_activity_level(self, activity: str) -> float:
        """ĞœĞ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ² Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ"""
        activity_map = {
            'very_low': 0.1, 'low': 0.3, 'medium': 0.5,
            'high': 0.7, 'very_high': 0.9, 'unknown': 0.5
        }
        return activity_map.get(activity, 0.5)
    
    def _calculate_spending_match(self, user_profile: Dict, product: Dict) -> float:
        """Ğ¡Ğ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ñ‚Ñ€Ğ°Ñ‚ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ¸ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ°"""
        user_spending = user_profile.get('total_spent', 0)
        product_value = product.get('business_value', 0.5)
        
        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ
        if user_spending > 50000 and product_value > 0.7:
            return 0.9
        elif user_spending > 20000 and product_value > 0.5:
            return 0.7
        elif user_spending > 5000:
            return 0.5
        else:
            return 0.3