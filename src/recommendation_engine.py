import polars as pl
import numpy as np
from typing import Dict, List, Tuple, Optional
from datetime import datetime, timedelta
import json
from pathlib import Path  # –î–û–ë–ê–í–¨–¢–ï –≠–¢–£ –°–¢–†–û–ö–£

from src.user_profiler import UserProfiler
from src.product_matcher import ProductMatcher
from utils.metrics import RecommendationMetrics
from utils.helpers import SystemHelpers, DataValidator

class AdvancedRecommendationEngine:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –¥–≤–∏–∂–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""
    
    def __init__(self, discovered_categories: Dict):
        self.discovered_categories = discovered_categories
        self.user_profiler = UserProfiler(discovered_categories)
        self.product_matcher = ProductMatcher(discovered_categories)
        self.metrics_calculator = RecommendationMetrics()
        self.helpers = SystemHelpers()
        
        # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self._user_profiles_cache = {}
        self._recommendations_cache = {}
    
    # ... –æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π ...
        
    def generate_recommendations(self, users_df: pl.DataFrame, 
                           events_df: pl.DataFrame, 
                           items_df: pl.DataFrame,
                           optimization_strategy: str = "balanced") -> pl.DataFrame:  # –£–ë–ò–†–ê–ï–ú use_ml
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å ML/LLM
        """
        print(f"üéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π (—Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {optimization_strategy})...")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        user_profiles = self.user_profiler.create_user_profiles(users_df, events_df, items_df)
        
        if user_profiles.height == 0:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ—Ñ–∏–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
            return pl.DataFrame()
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å ML/LLM (–í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–µ–º ML)
        recommendations = self.product_matcher.match_users_to_products(user_profiles, use_ml=True)
        
        if recommendations.height == 0:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
            return pl.DataFrame()
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        optimized_recommendations = self._apply_optimization_strategy(
            recommendations, optimization_strategy
        )
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        validation_results = DataValidator.validate_recommendations(optimized_recommendations)
        
        if not validation_results['validation_passed']:
            print("‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
            for issue in validation_results.get('business_rules_violations', []):
                print(f"   - {issue}")
        
        print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {optimized_recommendations.height}")
        
        return optimized_recommendations
    
    def _apply_optimization_strategy(self, recommendations: pl.DataFrame, 
                               strategy: str) -> pl.DataFrame:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º"""
        
        if strategy == "coverage":
            return self._optimize_for_coverage(recommendations)
        elif strategy == "revenue":
            return self._optimize_for_revenue(recommendations)
        elif strategy == "engagement":
            return self._optimize_for_engagement(recommendations)
        else:  # balanced
            return self._optimize_balanced(recommendations)

    def _optimize_for_coverage(self, recommendations: pl.DataFrame) -> pl.DataFrame:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
        print("   üéØ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ø-1 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –ø–æ final_score
        optimized = (
            recommendations.sort(['user_id', 'final_score'], descending=[False, True])
            .group_by('user_id')
            .head(1)
        )
        
        return optimized

    def _optimize_for_revenue(self, recommendations: pl.DataFrame) -> pl.DataFrame:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏–∏ –±–∏–∑–Ω–µ—Å-—Ü–µ–Ω–Ω–æ—Å—Ç–∏"""
        print("   üí∞ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –ú–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è –±–∏–∑–Ω–µ—Å-—Ü–µ–Ω–Ω–æ—Å—Ç–∏")
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è final_score –∏ business_value
        optimized = recommendations.with_columns([
            (pl.col('final_score') * 0.4 + pl.col('business_value') * 0.6)
            .alias('revenue_score')
        ]).sort(['user_id', 'revenue_score'], descending=[False, True])
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ø —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ revenue_score
        optimized = (
            optimized.group_by('user_id')
            .agg([
                pl.col('product_id').first().alias('product_id'),
                pl.col('product_name').first().alias('product_name'),
                pl.col('product_type').first().alias('product_type'),
                pl.col('base_match_score').first().alias('base_match_score'),
                pl.col('final_score').first().alias('final_score'),
                pl.col('business_value').first().alias('business_value'),
                pl.col('reasoning').first().alias('reasoning'),
                pl.col('llm_explanation').first().alias('llm_explanation'),
                pl.col('ml_enhanced').first().alias('ml_enhanced'),
                pl.col('llm_enhanced').first().alias('llm_enhanced'),
                pl.col('revenue_score').first().alias('final_score')  # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º final_score
            ])
        )
        
        return optimized

    def _optimize_for_engagement(self, recommendations: pl.DataFrame) -> pl.DataFrame:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –≤–æ–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
        print("   üî• –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –ú–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è –≤–æ–≤–ª–µ—á–µ–Ω–∏—è")
        
        # –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ —Å –≤—ã—Å–æ–∫–∏–º final_score
        optimized = (
            recommendations.sort(['user_id', 'final_score'], descending=[False, True])
            .group_by('user_id')
            .agg([
                pl.col('product_id').first().alias('product_id'),
                pl.col('product_name').first().alias('product_name'),
                pl.col('product_type').first().alias('product_type'),
                pl.col('base_match_score').first().alias('base_match_score'),
                pl.col('final_score').first().alias('final_score'),
                pl.col('business_value').first().alias('business_value'),
                pl.col('reasoning').first().alias('reasoning'),
                pl.col('llm_explanation').first().alias('llm_explanation'),
                pl.col('ml_enhanced').first().alias('ml_enhanced'),
                pl.col('llm_enhanced').first().alias('llm_enhanced')
            ])
        )
        
        return optimized

    def _optimize_balanced(self, recommendations: pl.DataFrame) -> pl.DataFrame:
        """–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è"""
        print("   ‚öñÔ∏è –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥")
        
        # –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å—é –∏ –±–∏–∑–Ω–µ—Å-—Ü–µ–Ω–Ω–æ—Å—Ç—å—é
        optimized = recommendations.with_columns([
            (pl.col('final_score') * 0.6 + pl.col('business_value') * 0.4)
            .alias('balanced_score')
        ]).sort(['user_id', 'balanced_score'], descending=[False, True])
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º –¥–æ 3 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        optimized = (
            optimized.group_by('user_id')
            .head(3)
            .with_columns(pl.col('balanced_score').alias('final_score'))  # –û–±–Ω–æ–≤–ª—è–µ–º final_score
            .drop('balanced_score')  # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ª–æ–Ω–∫—É
        )
        
        return optimized
    
    def generate_personalized_explanations(self, recommendations: pl.DataFrame, 
                                         user_profiles: pl.DataFrame) -> pl.DataFrame:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        print("üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π...")
        
        explanations = []
        
        for rec in recommendations.iter_rows(named=True):
            user_profile = user_profiles.filter(pl.col('user_id') == rec['user_id'])
            
            if user_profile.height > 0:
                profile = user_profile.row(0, named=True)
                explanation = self._create_detailed_explanation(rec, profile)
            else:
                explanation = "–ù–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
            
            explanations.append({
                'user_id': rec['user_id'],
                'product_id': rec['product_id'],
                'explanation': explanation,
                'confidence_level': self._get_confidence_level(rec['match_score'])
            })
        
        return pl.DataFrame(explanations)
    
    def _create_detailed_explanation(self, recommendation: Dict, user_profile: Dict) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        product_name = recommendation['product_name']
        match_score = recommendation['match_score']
        
        explanation_parts = [f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º {product_name} –ø–æ—Ç–æ–º—É —á—Ç–æ:"]
        
        # –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –∞—Å–ø–µ–∫—Ç—ã
        if user_profile.get('spending_level') in ['high', 'very_high']:
            explanation_parts.append("‚Ä¢ —É –≤–∞—Å –≤—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å —Ç—Ä–∞—Ç, –ø–æ–¥—Ö–æ–¥—è—â–∏–π –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞")
        
        if user_profile.get('avg_transaction_value', 0) > 20000:
            explanation_parts.append("‚Ä¢ —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –≤–∞—à–∏—Ö –ø–æ–∫—É–ø–æ–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–µ–º–∏–∞–ª—å–Ω—ã–º –ø—Ä–æ–¥—É–∫—Ç–∞–º")
        
        # –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã
        if user_profile.get('interaction_frequency') in ['high', 'very_high']:
            explanation_parts.append("‚Ä¢ –≤—ã –ø—Ä–æ—è–≤–ª—è–µ—Ç–µ –≤—ã—Å–æ–∫—É—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, —á—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
        
        if user_profile.get('preference_stability', 0) > 0.7:
            explanation_parts.append("‚Ä¢ –≤–∞—à–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è —Å—Ç–∞–±–∏–ª—å–Ω—ã, —á—Ç–æ —Å–Ω–∏–∂–∞–µ—Ç —Ä–∏—Å–∫–∏")
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
        category_affinity = user_profile.get('category_affinity', {})
        if category_affinity:
            top_category = next(iter(category_affinity.items()), None)
            if top_category and top_category[1] > 0.5:
                explanation_parts.append(f"‚Ä¢ –≤—ã —á–∞—Å—Ç–æ –ø–æ–∫—É–ø–∞–µ—Ç–µ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{top_category[0]}'")
        
        # –£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        if match_score > 0.8:
            explanation_parts.append("‚Ä¢ —ç—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–¥–µ–∞–ª—å–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤–∞—à–µ–º—É –ø—Ä–æ—Ñ–∏–ª—é")
        elif match_score > 0.6:
            explanation_parts.append("‚Ä¢ —ç—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Ö–æ—Ä–æ—à–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤–∞—à–µ–º—É –ø—Ä–æ—Ñ–∏–ª—é")
        else:
            explanation_parts.append("‚Ä¢ —ç—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ based –Ω–∞ –≤–∞—à–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏")
        
        return " ".join(explanation_parts)
    
    def _get_confidence_level(self, match_score: float) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
        if match_score > 0.8:
            return "very_high"
        elif match_score > 0.6:
            return "high"
        elif match_score > 0.4:
            return "medium"
        else:
            return "low"
    
    def analyze_recommendation_impact(self, recommendations: pl.DataFrame,
                                    user_profiles: pl.DataFrame) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        print("üìä –ê–Ω–∞–ª–∏–∑ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...")
        
        impact_analysis = {}
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        user_segments = self._segment_users(user_profiles)
        impact_analysis['user_segments'] = user_segments
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –ø—Ä–æ–¥—É–∫—Ç–æ–≤
        product_impact = self._analyze_product_impact(recommendations)
        impact_analysis['product_impact'] = product_impact
        
        # –û—Ü–µ–Ω–∫–∞ –æ–±—â–µ–≥–æ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è
        total_impact = self._estimate_total_impact(recommendations, user_profiles)
        impact_analysis['total_impact'] = total_impact
        
        return impact_analysis
    
    def _segment_users(self, user_profiles: pl.DataFrame) -> Dict:
        """–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        segments = {
            'high_value': user_profiles.filter(pl.col('spending_level').is_in(['high', 'very_high'])),
            'medium_value': user_profiles.filter(pl.col('spending_level') == 'medium'),
            'low_value': user_profiles.filter(pl.col('spending_level').is_in(['low', 'very_low'])),
            'high_activity': user_profiles.filter(pl.col('interaction_frequency').is_in(['high', 'very_high'])),
            'new_users': user_profiles.filter(pl.col('total_interactions') < 10)
        }
        
        segment_stats = {}
        for name, segment_df in segments.items():
            segment_stats[name] = {
                'count': segment_df.height,
                'percentage': segment_df.height / user_profiles.height,
                'avg_spending': segment_df['total_spent'].mean() if segment_df.height > 0 else 0
            }
        
        return segment_stats
    
    def _analyze_product_impact(self, recommendations: pl.DataFrame) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è –ø–æ —Ç–∏–ø–∞–º –ø—Ä–æ–¥—É–∫—Ç–æ–≤"""
        product_analysis = (
            recommendations.group_by('product_type')
            .agg([
                pl.count().alias('recommendation_count'),
                pl.col('match_score').mean().alias('avg_match_score'),
                pl.col('business_value').mean().alias('avg_business_value'),
                pl.col('final_score').mean().alias('avg_final_score'),
                pl.col('user_id').unique().count().alias('unique_users')
            ])
            .sort('recommendation_count', descending=True)
        )
        
        impact_by_product = {}
        for row in product_analysis.iter_rows(named=True):
            product_type = row['product_type']
            impact_by_product[product_type] = {
                'recommendation_count': row['recommendation_count'],
                'unique_users_reached': row['unique_users'],
                'avg_match_score': round(row['avg_match_score'], 3),
                'avg_business_value': round(row['avg_business_value'], 3),
                'avg_final_score': round(row['avg_final_score'], 3),
                'penetration_rate': row['unique_users'] / recommendations['user_id'].unique().length()
            }
        
        return impact_by_product
    
    def _estimate_total_impact(self, recommendations: pl.DataFrame, 
                             user_profiles: pl.DataFrame) -> Dict:
        """–û—Ü–µ–Ω–∫–∞ –æ–±—â–µ–≥–æ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        total_users = user_profiles.height
        users_with_recommendations = recommendations['user_id'].unique().length()
        
        # –û—Ü–µ–Ω–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –≤—ã—Ä—É—á–∫–∏
        high_value_recommendations = recommendations.filter(pl.col('final_score') > 0.7)
        medium_value_recommendations = recommendations.filter(
            (pl.col('final_score') > 0.5) & (pl.col('final_score') <= 0.7)
        )
        
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –∫–æ–Ω–≤–µ—Ä—Å–∏–∏
        high_value_conversion_rate = 0.25  # 25% –¥–ª—è –≤—ã—Å–æ–∫–∏—Ö scores
        medium_value_conversion_rate = 0.15  # 15% –¥–ª—è —Å—Ä–µ–¥–Ω–∏—Ö scores
        low_value_conversion_rate = 0.05   # 5% –¥–ª—è –Ω–∏–∑–∫–∏—Ö scores
        
        # –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –ø–æ —Ç–∏–ø–∞–º
        product_value_map = {
            'premium_cards': 75000,
            'credit_cards': 25000,
            'savings': 50000,
            'investment': 100000,
            'insurance': 30000
        }
        
        estimated_revenue = 0
        conversion_breakdown = {}
        
        for product_type in recommendations['product_type'].unique().to_list():
            type_recommendations = recommendations.filter(pl.col('product_type') == product_type)
            product_value = product_value_map.get(product_type, 20000)
            
            high_value_count = type_recommendations.filter(pl.col('final_score') > 0.7).height
            medium_value_count = type_recommendations.filter(
                (pl.col('final_score') > 0.5) & (pl.col('final_score') <= 0.7)
            ).height
            low_value_count = type_recommendations.filter(pl.col('final_score') <= 0.5).height
            
            type_revenue = (
                high_value_count * high_value_conversion_rate * product_value +
                medium_value_count * medium_value_conversion_rate * product_value +
                low_value_count * low_value_conversion_rate * product_value
            )
            
            estimated_revenue += type_revenue
            conversion_breakdown[product_type] = {
                'estimated_conversions': round(
                    high_value_count * high_value_conversion_rate +
                    medium_value_count * medium_value_conversion_rate +
                    low_value_count * low_value_conversion_rate
                ),
                'estimated_revenue': round(type_revenue),
                'avg_product_value': product_value
            }
        
        return {
            'estimated_total_revenue': round(estimated_revenue),
            'user_coverage_rate': users_with_recommendations / total_users,
            'avg_recommendations_per_user': recommendations.height / users_with_recommendations,
            'conversion_breakdown': conversion_breakdown,
            'confidence_level': self._calculate_impact_confidence(recommendations)
        }
    
    def _calculate_impact_confidence(self, recommendations: pl.DataFrame) -> str:
        """–†–∞—Å—á–µ—Ç —É—Ä–æ–≤–Ω—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –æ—Ü–µ–Ω–∫–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è"""
        if recommendations.height == 0:
            return "very_low"
        
        avg_final_score = recommendations['final_score'].mean()
        high_confidence_recs = recommendations.filter(pl.col('final_score') > 0.7).height
        high_confidence_ratio = high_confidence_recs / recommendations.height
        
        if high_confidence_ratio > 0.5 and avg_final_score > 0.6:
            return "high"
        elif high_confidence_ratio > 0.3 and avg_final_score > 0.5:
            return "medium"
        elif high_confidence_ratio > 0.1:
            return "low"
        else:
            return "very_low"
    
    def generate_strategy_comparison(self, users_df: pl.DataFrame,
                                   events_df: pl.DataFrame,
                                   items_df: pl.DataFrame) -> Dict:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        print("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏...")
        
        strategies = ['coverage', 'revenue', 'engagement', 'balanced']
        comparison_results = {}
        
        user_profiles = self.user_profiler.create_user_profiles(users_df, events_df, items_df)
        
        for strategy in strategies:
            print(f"   –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: {strategy}")
            recommendations = self.generate_recommendations(
                users_df, events_df, items_df, strategy
            )
            
            if recommendations.height > 0:
                metrics = self.metrics_calculator.calculate_all_metrics(
                    recommendations, user_profiles
                )
                comparison_results[strategy] = {
                    'metrics': metrics,
                    'recommendation_count': recommendations.height,
                    'unique_users': recommendations['user_id'].unique().length()
                }
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        best_strategy = self._select_best_strategy(comparison_results)
        comparison_results['best_strategy'] = best_strategy
        
        return comparison_results
    
    def _select_best_strategy(self, comparison_results: Dict) -> Dict:
        """–í—ã–±–æ—Ä –ª—É—á—à–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫"""
        if not comparison_results:
            return {'strategy': 'balanced', 'reason': 'No data available'}
        
        strategy_scores = {}
        
        for strategy, results in comparison_results.items():
            if strategy == 'best_strategy':
                continue
                
            metrics = results['metrics']
            overall_score = metrics['overall_score']['overall_score']
            
            # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å —É—á–µ—Ç–æ–º –±–∏–∑–Ω–µ—Å-–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤
            business_score = metrics['business']['avg_business_value_per_rec']
            coverage_score = metrics['coverage']['user_coverage_rate']
            relevance_score = metrics['relevance']['avg_match_score']
            
            weighted_score = (
                business_score * 0.4 +
                coverage_score * 0.3 +
                relevance_score * 0.3
            )
            
            strategy_scores[strategy] = {
                'weighted_score': weighted_score,
                'overall_score': overall_score,
                'business_impact': metrics['business']['business_impact'],
                'user_coverage': coverage_score
            }
        
        # –í—ã–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º weighted_score
        best_strategy = max(strategy_scores.items(), key=lambda x: x[1]['weighted_score'])
        
        return {
            'strategy': best_strategy[0],
            'weighted_score': best_strategy[1]['weighted_score'],
            'overall_score': best_strategy[1]['overall_score'],
            'reason': f"–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –±–∏–∑–Ω–µ—Å-—Ü–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –ø–æ–∫—Ä—ã—Ç–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
        }
    
    def create_recommendation_report(self, recommendations: pl.DataFrame,
                                   user_profiles: pl.DataFrame,
                                   impact_analysis: Dict) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º"""
        report = []
        report.append("üìä –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –û–¢–ß–ï–¢ –ü–û –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø–ú")
        report.append("=" * 60)
        report.append("")
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_recommendations = recommendations.height
        unique_users = recommendations['user_id'].unique().length()
        total_users = user_profiles.height
        
        report.append("üìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        report.append(f"  ‚Ä¢ –í—Å–µ–≥–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {total_recommendations}")
        report.append(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {unique_users}")
        report.append(f"  ‚Ä¢ –ü–æ–∫—Ä—ã—Ç–∏–µ: {(unique_users/total_users)*100:.1f}%")
        report.append(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {total_recommendations/unique_users:.1f}")
        report.append("")
        
        # –¢–æ–ø —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º
        product_stats = (
            recommendations.group_by('product_name')
            .agg([
                pl.count().alias('count'),
                pl.col('final_score').mean().alias('avg_score')
            ])
            .sort('count', descending=True)
            .head(5)
        )
        
        report.append("üèÜ –¢–û–ü-5 –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–• –ü–†–û–î–£–ö–¢–û–í:")
        for row in product_stats.iter_rows(named=True):
            report.append(f"  ‚Ä¢ {row['product_name']}: {row['count']} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π (score: {row['avg_score']:.3f})")
        report.append("")
        
        # –ê–Ω–∞–ª–∏–∑ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è
        impact = impact_analysis['total_impact']
        report.append("üí∏ –û–¶–ï–ù–ö–ê –í–û–ó–î–ï–ô–°–¢–í–ò–Ø:")
        report.append(f"  ‚Ä¢ –û—Ü–µ–Ω–∫–∞ –æ–±—â–µ–π –≤—ã—Ä—É—á–∫–∏: {impact['estimated_total_revenue']:,.0f}‚ÇΩ")
        report.append(f"  ‚Ä¢ –£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {impact['confidence_level']}")
        report.append("")
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        segments = impact_analysis['user_segments']
        report.append("üë• –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –°–ï–ì–ú–ï–ù–¢–ê–ú:")
        for segment, stats in segments.items():
            report.append(f"  ‚Ä¢ {segment}: {stats['count']} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π ({stats['percentage']*100:.1f}%)")
        report.append("")
        
        # –ö–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        avg_final_score = recommendations['final_score'].mean()
        high_quality_recs = recommendations.filter(pl.col('final_score') > 0.7).height
        high_quality_ratio = high_quality_recs / total_recommendations
        
        report.append("üéØ –ö–ê–ß–ï–°–¢–í–û –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ô:")
        report.append(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π score: {avg_final_score:.3f}")
        report.append(f"  ‚Ä¢ –í—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {high_quality_ratio*100:.1f}%")
        report.append(f"  ‚Ä¢ –í—Å–µ–≥–æ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö: {high_quality_recs}")
        
        return "\n".join(report)
    
    def save_recommendation_analysis(self, recommendations: pl.DataFrame,
                                   user_profiles: pl.DataFrame,
                                   impact_analysis: Dict,
                                   filepath: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        analysis_data = {
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_recommendations': recommendations.height,
                'unique_users': recommendations['user_id'].unique().length(),
                'total_users': user_profiles.height,
                'avg_final_score': float(recommendations['final_score'].mean()),
                'total_estimated_revenue': impact_analysis['total_impact']['estimated_total_revenue']
            },
            'recommendations_sample': recommendations.head(100).to_dicts(),
            'impact_analysis': impact_analysis,
            'user_segments': impact_analysis['user_segments'],
            'product_impact': impact_analysis['product_impact']
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"üíæ –ê–Ω–∞–ª–∏–∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filepath}")
    
    def run_complete_analysis(self, users_df: pl.DataFrame,
                            events_df: pl.DataFrame,
                            items_df: pl.DataFrame,
                            output_dir: str = "results") -> Dict:
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–æ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã"""
        print("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê –†–ï–ö–û–ú–ï–ù–î–ê–¢–ï–õ–¨–ù–û–ô –°–ò–°–¢–ï–ú–´")
        print("=" * 60)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        Path(output_dir).mkdir(exist_ok=True)
        
        results = {}
        
        # 1. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        print("\n1. üîç –°–†–ê–í–ù–ï–ù–ò–ï –°–¢–†–ê–¢–ï–ì–ò–ô –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò")
        strategy_comparison = self.generate_strategy_comparison(users_df, events_df, items_df)
        results['strategy_comparison'] = strategy_comparison
        
        best_strategy = strategy_comparison['best_strategy']['strategy']
        print(f"   ‚úÖ –õ—É—á—à–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {best_strategy}")
        
        # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å –ª—É—á—à–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π
        print(f"\n2. üéØ –ì–ï–ù–ï–†–ê–¶–ò–Ø –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ô ({best_strategy} —Å—Ç—Ä–∞—Ç–µ–≥–∏—è)")
        recommendations = self.generate_recommendations(
            users_df, events_df, items_df, best_strategy
        )
        results['recommendations'] = recommendations
        
        # 3. –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π
        print(f"\n3. üë§ –°–û–ó–î–ê–ù–ò–ï –ü–†–û–§–ò–õ–ï–ô –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô")
        user_profiles = self.user_profiler.create_user_profiles(users_df, events_df, items_df)
        results['user_profiles'] = user_profiles
        
        # 4. –ê–Ω–∞–ª–∏–∑ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è
        print(f"\n4. üìä –ê–ù–ê–õ–ò–ó –í–û–ó–î–ï–ô–°–¢–í–ò–Ø –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ô")
        impact_analysis = self.analyze_recommendation_impact(recommendations, user_profiles)
        results['impact_analysis'] = impact_analysis
        
        # 5. –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
        print(f"\n5. üìà –†–ê–°–ß–ï–¢ –ú–ï–¢–†–ò–ö –ö–ê–ß–ï–°–¢–í–ê")
        metrics = self.metrics_calculator.calculate_all_metrics(recommendations, user_profiles)
        results['metrics'] = metrics
        
        # 6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
        print(f"\n6. üìù –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–ë–™–Ø–°–ù–ï–ù–ò–ô")
        explanations = self.generate_personalized_explanations(recommendations, user_profiles)
        results['explanations'] = explanations
        
        # 7. –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤
        print(f"\n7. üìÑ –°–û–ó–î–ê–ù–ò–ï –û–¢–ß–ï–¢–û–í")
        report = self.create_recommendation_report(recommendations, user_profiles, impact_analysis)
        metrics_report = self.metrics_calculator.generate_metrics_report(metrics)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        self.save_recommendation_analysis(
            recommendations, user_profiles, impact_analysis,
            f"{output_dir}/recommendation_analysis_{timestamp}.json"
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤
        with open(f"{output_dir}/executive_report_{timestamp}.txt", 'w', encoding='utf-8') as f:
            f.write(report)
        
        with open(f"{output_dir}/metrics_report_{timestamp}.txt", 'w', encoding='utf-8') as f:
            f.write(metrics_report)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations.write_parquet(f"{output_dir}/recommendations_{timestamp}.parquet")
        user_profiles.write_parquet(f"{output_dir}/user_profiles_{timestamp}.parquet")
        explanations.write_parquet(f"{output_dir}/explanations_{timestamp}.parquet")
        
        print(f"\n‚úÖ –ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}/")
        print(f"üìä –û—Ç—á–µ—Ç—ã: executive_report_{timestamp}.txt, metrics_report_{timestamp}.txt")
        
        return results