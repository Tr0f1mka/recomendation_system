import polars as pl
import numpy as np
from pathlib import Path
from typing import Any, Dict, List, Union
import json
import time
from datetime import datetime
import logging

class SystemHelpers:
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–∏—Å—Ç–µ–º—ã"""
    
    @staticmethod
    def setup_logging(log_file: str = "psb_recommendation.log"):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        return logging.getLogger(__name__)
    
    @staticmethod
    def timer(func):
        """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            end_time = time.time()
            print(f"‚è±Ô∏è  {func.__name__} –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∑–∞ {end_time - start_time:.2f} —Å–µ–∫—É–Ω–¥")
            return result
        return wrapper
    
    @staticmethod
    def safe_read_parquet(filepath: Path, **kwargs) -> pl.DataFrame:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ parquet —Ñ–∞–π–ª–æ–≤"""
        try:
            if filepath.exists():
                return pl.read_parquet(filepath, **kwargs)
            else:
                print(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}")
                return pl.DataFrame()
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {filepath}: {e}")
            return pl.DataFrame()
    
    @staticmethod
    def save_dataframe(df: pl.DataFrame, filepath: Path, verbose: bool = True):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ DataFrame —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        try:
            filepath.parent.mkdir(parents=True, exist_ok=True)
            df.write_parquet(filepath)
            if verbose:
                print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath} ({df.height} —Å—Ç—Ä–æ–∫)")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è {filepath}: {e}")
    
    @staticmethod
    def sample_dataframe(df: pl.DataFrame, sample_size: Union[int, float], 
                        random_state: int = 42) -> pl.DataFrame:
        """–°–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ DataFrame"""
        if df.height == 0:
            return df
        
        if isinstance(sample_size, float):
            sample_size = int(df.height * sample_size)
        
        sample_size = min(sample_size, df.height)
        return df.sample(n=sample_size, seed=random_state)
    
    @staticmethod
    def print_dataframe_info(df: pl.DataFrame, name: str = "DataFrame"):
        """–ü–µ—á–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ DataFrame"""
        if df.height == 0:
            print(f"üìä {name}: –ü—É—Å—Ç–æ–π DataFrame")
            return
        
        print(f"üìä {name}:")
        print(f"   –§–æ—Ä–º–∞: {df.height} —Å—Ç—Ä–æ–∫, {df.width} –∫–æ–ª–æ–Ω–æ–∫")
        print(f"   –ö–æ–ª–æ–Ω–∫–∏: {df.columns}")
        print(f"   –¢–∏–ø—ã: {df.dtypes}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∏—Å–ª–æ–≤—ã–º –∫–æ–ª–æ–Ω–∫–∞–º
        numeric_cols = [col for col in df.columns if df[col].dtype in [pl.Int64, pl.Float64]]
        if numeric_cols:
            print(f"   –ß–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {numeric_cols}")
    
    @staticmethod
    def merge_multiple_dataframes(df_list: List[pl.DataFrame], on: str = 'user_id') -> pl.DataFrame:
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö DataFrame"""
        if not df_list:
            return pl.DataFrame()
        
        result = df_list[0]
        for df in df_list[1:]:
            if df.height > 0:
                result = result.join(df, on=on, how='left')
        
        return result
    
    @staticmethod
    def detect_outliers_iqr(df: pl.DataFrame, column: str) -> Dict:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ –º–µ—Ç–æ–¥–æ–º IQR"""
        if column not in df.columns:
            return {}
        
        values = df[column].drop_nulls()
        if values.len() == 0:
            return {}
        
        q1 = values.quantile(0.25)
        q3 = values.quantile(0.75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        
        outliers = df.filter(
            (pl.col(column) < lower_bound) | (pl.col(column) > upper_bound)
        )
        
        return {
            'outlier_count': outliers.height,
            'outlier_percentage': outliers.height / df.height,
            'bounds': {'lower': lower_bound, 'upper': upper_bound},
            'outliers_sample': outliers.select([column]).head(5).to_dicts()
        }

class DataValidator:
    """–ö–ª–∞—Å—Å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö"""
    
    @staticmethod
    def validate_user_profiles(profiles: pl.DataFrame) -> Dict:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π"""
        validation_results = {
            'total_profiles': profiles.height,
            'missing_values': {},
            'data_quality_issues': [],
            'validation_passed': True
        }
        
        if profiles.height == 0:
            validation_results['validation_passed'] = False
            validation_results['data_quality_issues'].append("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π")
            return validation_results
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        required_fields = ['user_id', 'total_spent', 'spending_level']
        for field in required_fields:
            if field not in profiles.columns:
                validation_results['data_quality_issues'].append(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ: {field}")
                validation_results['validation_passed'] = False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        for column in profiles.columns:
            null_count = profiles[column].null_count()
            if null_count > 0:
                validation_results['missing_values'][column] = {
                    'count': null_count,
                    'percentage': null_count / profiles.height
                }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        if 'total_spent' in profiles.columns:
            negative_spending = profiles.filter(pl.col('total_spent') < 0).height
            if negative_spending > 0:
                validation_results['data_quality_issues'].append(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–∞—Ç—ã: {negative_spending} –∑–∞–ø–∏—Å–µ–π")
        
        return validation_results
    
    @staticmethod
    def validate_recommendations(recommendations: pl.DataFrame) -> Dict:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        validation_results = {
            'total_recommendations': recommendations.height,
            'score_validation': {},
            'business_rules_violations': [],
            'validation_passed': True
        }
        
        if recommendations.height == 0:
            validation_results['validation_passed'] = False
            validation_results['business_rules_violations'].append("–ù–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
            return validation_results
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ scores
        if 'match_score' in recommendations.columns:
            invalid_scores = recommendations.filter(
                (pl.col('match_score') < 0) | (pl.col('match_score') > 1)
            ).height
            if invalid_scores > 0:
                validation_results['score_validation']['invalid_match_scores'] = invalid_scores
                validation_results['validation_passed'] = False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        duplicates = recommendations.filter(
            pl.col('user_id').is_duplicated() & pl.col('product_id').is_duplicated()
        ).height
        if duplicates > 0:
            validation_results['business_rules_violations'].append(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {duplicates}")
        
        return validation_results

class FormatHelpers:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã–≤–æ–¥–∞"""
    
    @staticmethod
    def format_currency(amount: float) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∞–ª—é—Ç—ã"""
        if amount >= 1_000_000:
            return f"{amount/1_000_000:.1f}M‚ÇΩ"
        elif amount >= 1_000:
            return f"{amount/1_000:.1f}K‚ÇΩ"
        else:
            return f"{amount:.0f}‚ÇΩ"
    
    @staticmethod
    def format_percentage(value: float) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤"""
        return f"{value*100:.1f}%"
    
    @staticmethod
    def format_large_number(number: int) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–æ–ª—å—à–∏—Ö —á–∏—Å–µ–ª"""
        if number >= 1_000_000:
            return f"{number/1_000_000:.1f}M"
        elif number >= 1_000:
            return f"{number/1_000:.1f}K"
        else:
            return f"{number}"
    
    @staticmethod
    def create_progress_bar(iteration: int, total: int, length: int = 50) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞"""
        percent = ("{0:.1f}").format(100 * (iteration / float(total)))
        filled_length = int(length * iteration // total)
        bar = '‚ñà' * filled_length + '‚îÄ' * (length - filled_length)
        return f"|{bar}| {percent}%"