from src.data_processor import DataProcessor
from src.recommendation_engine import AdvancedRecommendationEngine
from src.category_discovery import CategoryDiscoverer
from utils.metrics import RecommendationMetrics
import json
from datetime import datetime
import os
import polars as pl

def main():
    print("ðŸš€ Ð—ÐÐŸÐ£Ð¡Ðš Ð£Ð›Ð£Ð§Ð¨Ð•ÐÐÐžÐ™ Ð¡Ð˜Ð¡Ð¢Ð•ÐœÐ« Ð¡ ML/LLM")
    print("=" * 50)
    
    # 1. Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…
    print("ðŸ“Š 1. Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…...")
    processor = DataProcessor()
    data = processor.load_all_data(sample_fraction=0.1)
    
    if not data or 'retail_items' not in data or data['retail_items'].height == 0:
        print("âŒ ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸")
        return
    
    # 2. Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð»Ð¾Ð³Ð°Ñ€Ð¸Ñ„Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ†ÐµÐ½Ñ‹
    print("ðŸ”§ 2. Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð»Ð¾Ð³Ð°Ñ€Ð¸Ñ„Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ñ†ÐµÐ½...")
    data['retail_items'] = processor.fix_log_prices(data['retail_items'])
    
    # 3. ÐÐ½Ð°Ð»Ð¸Ð· ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
    print("ðŸ” 3. ÐÐ½Ð°Ð»Ð¸Ð· ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…...")
    processor.explore_data_structure(data)
    
    # 4. ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¹ Ð¸Ð· Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
    print("ðŸŽ¯ 4. ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¹ Ð¸Ð· Ð´Ð°Ð½Ð½Ñ‹Ñ…...")
    discoverer = CategoryDiscoverer()
    categories = discoverer.discover_categories_from_data(data['retail_items'])
    
    print(f"   ðŸ“ ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¹: {len(categories.get('existing_categories', {}).get('stats', []))}")
    
    # 5. Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð²Ð¸Ð¶ÐºÐ° Ñ Ñ€ÐµÐ°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸ÑÐ¼Ð¸
    print("ðŸ¤– 5. Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ML/LLM Ð´Ð²Ð¸Ð¶ÐºÐ°...")
    engine = AdvancedRecommendationEngine(discovered_categories=categories)
    
    # 6. Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹ Ñ ML
    print("ðŸŽ¯ 6. Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹...")
    recommendations = engine.generate_recommendations(
        users_df=data['users'],
        events_df=data['retail_events'], 
        items_df=data['retail_items'],
        optimization_strategy="balanced"
    )
    
    if recommendations.height == 0:
        print("âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸")
        return
    
    # 7. Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÐµÐ¹ Ð´Ð»Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
    print("ðŸ‘¤ 7. Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ñ… Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÐµÐ¹...")
    user_profiles = engine.user_profiler.create_user_profiles(
        data['users'], data['retail_events'], data['retail_items']
    )
    
    # 8. Ð Ð°ÑÑ‡ÐµÑ‚ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
    print("ðŸ“ˆ 8. Ð Ð°ÑÑ‡ÐµÑ‚ Ð¼ÐµÑ‚Ñ€Ð¸Ðº ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°...")
    metrics_calculator = RecommendationMetrics()
    metrics = metrics_calculator.calculate_all_metrics(recommendations, user_profiles)
    
    # 9. ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
    print("\n" + "=" * 60)
    print("ðŸŽ‰ Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð« Ð¡Ð˜Ð¡Ð¢Ð•ÐœÐ« Ð¡ ML/LLM")
    print("=" * 60)
    
    # ÐžÐ±Ñ‰Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
    print(f"ðŸ“Š ÐžÐ±Ñ‰Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°:")
    print(f"   â€¢ Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾: {recommendations.height}")
    print(f"   â€¢ Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹: {recommendations['user_id'].n_unique()}")
    print(f"   â€¢ Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð²: {recommendations['product_id'].n_unique()}")
    
    # ML/LLM ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
    if 'ml_enhanced' in recommendations.columns:
        ml_enhanced = recommendations.filter(pl.col('ml_enhanced') == True).height
        print(f"   â€¢ ML-Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾: {ml_enhanced} ({ml_enhanced/recommendations.height*100:.1f}%)")
    
    if 'llm_enhanced' in recommendations.columns:
        llm_enhanced = recommendations.filter(pl.col('llm_enhanced') == True).height
        print(f"   â€¢ LLM-Ð¾Ð±Ð¾Ð³Ð°Ñ‰ÐµÐ½Ð¾: {llm_enhanced} ({llm_enhanced/recommendations.height*100:.1f}%)")
    
    # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°
    print(f"ðŸŽ¯ ÐšÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹:")
    print(f"   â€¢ ÐžÐ±Ñ‰Ð¸Ð¹ score: {metrics['overall_score']['overall_score']}")
    print(f"   â€¢ Ð ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ: {metrics['relevance']['avg_match_score']}")
    print(f"   â€¢ ÐŸÐ¾ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ: {metrics['coverage']['user_coverage_rate'] * 100:.1f}%")
    print(f"   â€¢ Ð”Ð¸Ð²ÐµÑ€ÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ: {metrics['diversity']['diversity_index']}")
    
    # ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹ - Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐÐ«Ð™ ÐšÐžÐ”
    print(f"\nðŸ“‹ ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¹:")
    sample_recs = recommendations.head(3)
    for i, rec in enumerate(sample_recs.iter_rows(named=True), 1):
        # Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐ˜Ð•: Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¸ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ user_id
        user_id = rec.get('user_id', 'unknown')
        if isinstance(user_id, (int, float)):
            user_id_str = str(int(user_id))
        else:
            user_id_str = str(user_id)
        
        product_name = rec.get('product_name', 'unknown')
        final_score = rec.get('final_score', 0)
        
        print(f"   {i}. ðŸ‘¤ {user_id_str[:8]}... â†’ ðŸ“¦ {product_name}")
        print(f"      â­ Score: {final_score}")
        
        if 'llm_explanation' in rec and rec['llm_explanation']:
            explanation = rec['llm_explanation']
            if len(explanation) > 80:
                explanation = explanation[:77] + "..."
            print(f"      ðŸ’¡ {explanation}")
            
        if i < 3:
            print()
    
    # 10. Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
    print(f"\nðŸ’¾ 9. Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²...")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ð°Ð¿ÐºÑƒ results ÐµÑÐ»Ð¸ Ð½ÐµÑ‚
    os.makedirs("results", exist_ok=True)
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸
    recommendations.write_parquet(f"results/recommendations_{timestamp}.parquet")
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
    with open(f"results/metrics_{timestamp}.json", 'w', encoding='utf-8') as f:
        json.dump(metrics, f, ensure_ascii=False, indent=2)
    
    # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ñ‡ÐµÑ‚
    report = metrics_calculator.generate_metrics_report(metrics)
    with open(f"results/report_{timestamp}.txt", 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð² Ð¿Ð°Ð¿ÐºÐµ 'results/'")
    print(f"   â€¢ recommendations_{timestamp}.parquet")
    print(f"   â€¢ metrics_{timestamp}.json") 
    print(f"   â€¢ report_{timestamp}.txt")

if __name__ == "__main__":
    main()